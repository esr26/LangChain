{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have feelings, but I'm here and ready to assist you!\\n\\nThat's great! It's wonderful to connect with another AI Engineer. What can I do for you today?  Perhaps you have a question about a particular AI model, need help with code, or want to discuss the latest advancements in the field? ðŸ˜„  \\n\\nLet me know how I can be helpful!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 20, 'total_tokens': 110, 'completion_time': 0.163636364, 'prompt_time': 8.606e-05, 'queue_time': 0.024551829, 'total_time': 0.163722424}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-db001a94-dcda-4cd6-8151-b1121d75cada-0', usage_metadata={'input_tokens': 20, 'output_tokens': 90, 'total_tokens': 110})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, How are you and I am a AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Raj and that you are a Data Scientist.  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm curious to learn more!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 69, 'total_tokens': 113, 'completion_time': 0.08, 'prompt_time': 0.001865804, 'queue_time': 0.021534646, 'total_time': 0.081865804}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-11c87890-e3b4-4191-a88a-61d1528680f7-0', usage_metadata={'input_tokens': 69, 'output_tokens': 44, 'total_tokens': 113})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Raj and I am a Data scientist\"),\n",
    "        AIMessage(content=\"Hello Raj! It's nice to meet you. \\n\\nAs a Data scientist, what kind of problems do you solve?\" ),\n",
    "        HumanMessage(content=\"Hey, What's my name and What I do?\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "past_conversation = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in past_conversation:\n",
    "        past_conversation[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    return past_conversation[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Raj and I am a Data scientist\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Raj, it's great to meet you!\\n\\nBeing a Data Scientist is such a fascinating field.  What kind of projects are you currently working on? \\n\\nDo you have a particular area of data science that you specialize in, like machine learning, deep learning, or data visualization?  I'm always eager to learn more about the exciting work people are doing in this area. ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking whether the model remembers my information from stored chat\n",
    "config_1 = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Raj. ðŸ˜Š  \\n\\nI remember that you introduced yourself at the beginning of our conversation!  \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, My name is Raj and I am a Data scientist', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Raj, it's nice to meet you! \\n\\nWhat can I do for you today? Are you working on any interesting projects? \\n\\nI'm eager to learn more about your work in data science.  ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 21, 'total_tokens': 71, 'completion_time': 0.090909091, 'prompt_time': 0.001232596, 'queue_time': 0.033480153, 'total_time': 0.092141687}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c5d730d-c48f-4c93-a59e-3fe06f3a7a25-0', usage_metadata={'input_tokens': 21, 'output_tokens': 50, 'total_tokens': 71}), HumanMessage(content='Hi, My name is Raj and I am a Data scientist', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Raj, it's great to meet you!\\n\\nBeing a Data Scientist is such a fascinating field.  What kind of projects are you currently working on? \\n\\nDo you have a particular area of data science that you specialize in, like machine learning, deep learning, or data visualization?  I'm always eager to learn more about the exciting work people are doing in this area. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 91, 'total_tokens': 177, 'completion_time': 0.156363636, 'prompt_time': 0.00347534, 'queue_time': 0.023075138999999998, 'total_time': 0.159838976}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0de96a47-2f0f-4311-9eb6-6e5c35921cb8-0', usage_metadata={'input_tokens': 91, 'output_tokens': 86, 'total_tokens': 177}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Raj. ðŸ˜Š  \\n\\nI remember that you introduced yourself at the beginning of our conversation!  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 190, 'total_tokens': 216, 'completion_time': 0.047272727, 'prompt_time': 0.007100509, 'queue_time': 0.026177469000000002, 'total_time': 0.054373236}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bf5134e2-6937-4d5b-ba9d-e68ff60d6d96-0', usage_metadata={'input_tokens': 190, 'output_tokens': 26, 'total_tokens': 216})])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
